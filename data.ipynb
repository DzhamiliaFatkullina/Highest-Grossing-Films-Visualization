{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director_and_country(link):\n",
    "    \"\"\"\n",
    "    Retrieves the director's name and country of origin for a given film title\n",
    "    from its Wikipedia page.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the film.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the director's name and the country of origin.\n",
    "               Returns (None, None) if the information is not found or if an error occurs.\n",
    "    \"\"\"\n",
    "    response = requests.get(link)\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    infobox = soup.find('table', {'class': 'infobox vevent'})\n",
    "\n",
    "    if infobox is None:\n",
    "        print(\"No infobox found on this page.\")\n",
    "        return None\n",
    "\n",
    "    director = []\n",
    "    countries = []\n",
    "\n",
    "    # Find director(s)\n",
    "    director_row = infobox.find('th', string='Directed by')\n",
    "    if not director_row:\n",
    "        country_row = infobox.find('th', string='director')\n",
    "    if director_row:\n",
    "        director_values = director_row.find_next('td')\n",
    "        if director_values:\n",
    "            director_html = re.findall(r'<td class=\"infobox-data\">(.*?)</td>', str(director_values))\n",
    "            # Directly parse the country_values Tag object\n",
    "            if director_values.find(\"ul\"):  # Check for <ul> tag indicating a list of countries\n",
    "                for li in director_values.find_all(\"li\"):\n",
    "                    dire = re.sub(r'<.*?>|\\[.*?\\]', '', li.text).strip()\n",
    "                    director.append(dire)\n",
    "            else:\n",
    "                match = re.search(r'<a.*?>(.*?)</a>', str(director_html))\n",
    "                director = [c.strip() for c in match.group(1).split(\"<br/>\")]\n",
    "\n",
    "\n",
    "    # Find country(ies)\n",
    "    country_row = infobox.find('th', string='Country')\n",
    "    if not country_row:\n",
    "        country_row = infobox.find('th', string='Country of origin')\n",
    "    if not country_row:\n",
    "        country_row = infobox.find('th', string='Countries')\n",
    "    if country_row:\n",
    "        country_values = country_row.find_next('td')\n",
    "        if country_values:\n",
    "            country_html = re.findall(r'<td class=\"infobox-data\">(.*?)</td>', str(country_values))\n",
    "            # Directly parse the country_values Tag object\n",
    "            if country_values.find(\"ul\"):  # Check for <ul> tag indicating a list of countries\n",
    "                for li in country_values.find_all(\"li\"):\n",
    "                    country = re.sub(r'<.*?>|\\[.*?\\]', '', li.text).strip()\n",
    "                    countries.append(country)\n",
    "            else:\n",
    "                countries = [c.strip() for c in str(country_html)[2:-2].split(\"<br/>\")]\n",
    "\n",
    "    \n",
    "    return director, countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:45: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\$'\n",
      "C:\\Users\\Джамиля\\AppData\\Local\\Temp\\ipykernel_16084\\3025535033.py:45: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df['Worldwide gross'] = df['Worldwide gross'].replace({'.*\\$': '', ',': ''}, regex=True).astype(int)\n"
     ]
    }
   ],
   "source": [
    "def get_film_data():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error during the GET request: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', class_='wikitable')\n",
    "    data = []\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cells = row.find_all(['td', 'th'])  # Include th for header and row headers\n",
    "            row_data = []\n",
    "            for cell in cells:\n",
    "                #if there is a link, extract it\n",
    "                link = cell.find('a')\n",
    "                if link and 'href' in link.attrs and 'title' in link.attrs:\n",
    "                    url = f\"https://en.wikipedia.org{link['href']}\"\n",
    "                else:\n",
    "                    url = None\n",
    "                text = cell.get_text(strip=True)\n",
    "                row_data.append(text)\n",
    "                if url:\n",
    "                    row_data.append(url)\n",
    "            data.append(row_data)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.iloc[1:]  # Skip the original header row\n",
    "\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.rename(columns={df.columns[2]: 'Title', \n",
    "                            df.columns[4]: 'Worldwide gross', \n",
    "                            df.columns[5]: 'Year',\n",
    "                            df.columns[6]: 'Ref',\n",
    "                            df.columns[0]: 'Rank',\n",
    "                            df.columns[1]: 'Peak',\n",
    "                            df.columns[3]: 'Link'})\n",
    "\n",
    "    # change to appropriate types\n",
    "    try:\n",
    "        df['Title'] = df['Title'].astype(str).replace('†', '', regex=True) \n",
    "        df['Worldwide gross'] = df['Worldwide gross'].replace({'.*\\$': '', ',': ''}, regex=True).astype(int)\n",
    "        df['Year'] = df['Year'].astype(int)\n",
    "        df['Rank'] = df['Rank'].astype(int)\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Column '{e}' not found. Please check your column names.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: Could not convert data type.  Check the contents of the columns. {e}\")\n",
    "\n",
    "    # add columns for directors and countries\n",
    "    directors = []\n",
    "    countries = []\n",
    "    for title in df['Link']:\n",
    "        director, country = get_director_and_country(title)\n",
    "        directors.append(director)\n",
    "        countries.append(country)\n",
    "\n",
    "\n",
    "    df['Director'] = directors\n",
    "    df['Country'] = countries\n",
    "\n",
    "    df = df.drop(['Peak', 'Ref', 'Link'], axis=1)\n",
    "    df.to_csv('output.txt', sep='|', index=False)\n",
    "    return pd.DataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Load variables from .env file for security reasons\n",
    "\n",
    "DB_NAME = os.environ.get(\"DB_NAME\")\n",
    "DB_USER = os.environ.get(\"DB_USER\")\n",
    "DB_PASSWORD = os.environ.get(\"DB_PASSWORD\")\n",
    "DB_HOST = os.environ.get(\"DB_HOST\")\n",
    "DB_PORT = os.environ.get(\"DB_PORT\")\n",
    "\n",
    "TABLE_NAME = \"HighestGrossingFilms\"\n",
    "\n",
    "def connect_to_db(db_name, db_user, db_password, db_host, db_port):\n",
    "    \"\"\"Connects to the PostgreSQL database.\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_password,\n",
    "            host=db_host,\n",
    "            port=db_port\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_table(conn, table_name):\n",
    "    \"\"\"Creates the table if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        create_table_sql = sql.SQL(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {} (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                title TEXT NOT NULL,\n",
    "                worldwide_gross BIGINT, \n",
    "                release_year INTEGER,\n",
    "                director TEXT[],  \n",
    "                country TEXT[] \n",
    "            );\n",
    "        \"\"\").format(sql.Identifier(table_name))\n",
    "\n",
    "        cur.execute(create_table_sql)\n",
    "        conn.commit()\n",
    "        # print(f\"Table '{table_name}' created successfully (if it didn't exist).\")\n",
    "        cur.close()\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "        conn.rollback()  # Rollback in case of error\n",
    "\n",
    "def insert_data(conn, df, table_name):\n",
    "    \"\"\"Inserts the DataFrame data into the PostgreSQL table.\"\"\"\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        # Prepare the SQL INSERT statement using parameterized queries to prevent SQL injection\n",
    "        insert_sql = sql.SQL(\"\"\"\n",
    "            INSERT INTO {} (id, title, worldwide_gross, release_year, director, country)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        \"\"\").format(sql.Identifier(table_name))\n",
    "\n",
    "        # Iterate through the DataFrame rows and insert data\n",
    "        for index, row in df.iterrows():\n",
    "            director = list(row['Director']) if isinstance(row['Director'], (list, tuple, pd.Series)) else [row['Director']] if row['Director'] else None # Convert to lists.\n",
    "            country = list(row['Country']) if isinstance(row['Country'], (list, tuple, pd.Series)) else [row['Country']] if row['Country'] else None\n",
    "\n",
    "            try:\n",
    "                cur.execute(insert_sql, (row['Rank'], row['Title'], row['Worldwide gross'], row['Year'], director, country))\n",
    "            except psycopg2.Error as e:\n",
    "                # print(f\"Error inserting row {index}: {e}\")\n",
    "                # print(f\"Data: {row.to_dict()}\") \n",
    "                conn.rollback()\n",
    "                continue \n",
    "\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        # print(f\"Error inserting data: {e}\")\n",
    "        conn.rollback()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'HighestGrossingFilms' created successfully (if it didn't exist).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = get_film_data()\n",
    "    conn = connect_to_db(DB_NAME, DB_USER, DB_PASSWORD, DB_HOST, DB_PORT)\n",
    "\n",
    "    if conn:\n",
    "        create_table(conn, TABLE_NAME)\n",
    "        insert_data(conn, df, TABLE_NAME)\n",
    "        conn.close()\n",
    "    else:\n",
    "        print(\"Failed to establish database connection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
