{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director_and_country(link):\n",
    "    \"\"\"\n",
    "    Retrieves the director's name and country of origin for a given film title\n",
    "    from its Wikipedia page.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the film.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the director's name and the country of origin.\n",
    "               Returns (None, None) if the information is not found or if an error occurs.\n",
    "    \"\"\"\n",
    "    response = requests.get(link)\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    infobox = soup.find('table', {'class': 'infobox vevent'})\n",
    "\n",
    "    if infobox is None:\n",
    "        print(\"No infobox found on this page.\")\n",
    "        return None\n",
    "\n",
    "    director = []\n",
    "    country = []\n",
    "\n",
    "    # Find director(s)\n",
    "    director_row = infobox.find('th', string='Directed by')\n",
    "    if not director_row:\n",
    "        country_row = infobox.find('th', string='director')\n",
    "    if director_row:\n",
    "        director_values = director_row.find_next('td')\n",
    "        if director_values:\n",
    "            for link in director_values.find_all('a', href=True):\n",
    "                director.append(re.sub(r'[^a-zA-Z\\s]', '', link.get_text()).strip()) # Extract text from links, TODO make directors a list of correct strings\n",
    "\n",
    "\n",
    "    # Find country(ies)\n",
    "    country_row = infobox.find('th', string='Country')\n",
    "    if not country_row:\n",
    "        country_row = infobox.find('th', string='Country of origin')\n",
    "    if not country_row:\n",
    "        country_row = infobox.find('th', string='Countries')\n",
    "    if country_row:\n",
    "        country_values = country_row.find_next('td')\n",
    "        if country_values:\n",
    "            plain_text = country_values.get_text(strip=True)  # Get all text, stripped\n",
    "            if plain_text:\n",
    "                countries = [re.sub(r'[^a-zA-Z\\s]', '', c).strip() for c in plain_text.split(',')] # TODO make country a list of correct strings\n",
    "                country.extend(countries)\n",
    "    \n",
    "    return director, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:46: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:46: SyntaxWarning: invalid escape sequence '\\$'\n",
      "C:\\Users\\Джамиля\\AppData\\Local\\Temp\\ipykernel_30528\\1874646161.py:46: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df['Worldwide gross'] = df['Worldwide gross'].replace({'.*\\$': '', ',': ''}, regex=True).astype(int)\n"
     ]
    }
   ],
   "source": [
    "def get_film_data():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error during the GET request: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', class_='wikitable')\n",
    "    data = []\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cells = row.find_all(['td', 'th'])  # Include th for header and row headers\n",
    "            row_data = []\n",
    "            for cell in cells:\n",
    "                #if there is a link, extract it\n",
    "                link = cell.find('a')\n",
    "                if link and 'href' in link.attrs and 'title' in link.attrs:\n",
    "                    url = f\"https://en.wikipedia.org{link['href']}\"\n",
    "                else:\n",
    "                    url = None\n",
    "                text = cell.get_text(strip=True)\n",
    "                row_data.append(text)\n",
    "                if url:\n",
    "                    row_data.append(url)\n",
    "            data.append(row_data)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.iloc[1:]  # Skip the original header row\n",
    "\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.rename(columns={df.columns[2]: 'Title', \n",
    "                            df.columns[4]: 'Worldwide gross', \n",
    "                            df.columns[5]: 'Year',\n",
    "                            df.columns[6]: 'Ref',\n",
    "                            df.columns[0]: 'Rank',\n",
    "                            df.columns[1]: 'Peak',\n",
    "                            df.columns[3]: 'Link'})\n",
    "\n",
    "    # change to appropriate types\n",
    "    try:\n",
    "        df['Title'] = df['Title'].astype(str).replace('†', '', regex=True) \n",
    "        df['Worldwide gross'] = df['Worldwide gross'].replace({'.*\\$': '', ',': ''}, regex=True).astype(int)\n",
    "        df['Year'] = df['Year'].astype(int)\n",
    "        df['Rank'] = df['Rank'].astype(int)\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Column '{e}' not found. Please check your column names.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: Could not convert data type.  Check the contents of the columns. {e}\")\n",
    "\n",
    "    # add columns for directors and countries\n",
    "    directors = []\n",
    "    countries = []\n",
    "    for title in df['Link']:\n",
    "        director, country = get_director_and_country(title)\n",
    "        directors.append(director)\n",
    "        countries.append(country)\n",
    "\n",
    "\n",
    "    df['Director'] = directors\n",
    "    df['Country'] = countries\n",
    "\n",
    "    df = df.drop(['Peak', 'Ref', 'Link'], axis=1)\n",
    "    df.to_csv('output.txt', sep='|', index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    get_film_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
